{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import ta\n",
    "import optuna\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random=1234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/Rerris/Technical_Analysis_Proyect/main/data/aapl_1d_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    response = requests.get(url, verify=True)\n",
    "    data = pd.read_csv(StringIO(response.text))\n",
    "    data=data[\"Close\"]\n",
    "    data=pd.DataFrame(data)\n",
    "    data[\"Closet-1\"]=data[\"Close\"].shift(-1)\n",
    "    data[\"Closet-2\"]=data[\"Close\"].shift(-2)\n",
    "    rsi_indicator = ta.momentum.RSIIndicator(close=data['Close'], window=14)\n",
    "    data['RSI'] = rsi_indicator.rsi()\n",
    "    #MACD\n",
    "    macd_indicator = ta.trend.MACD(close=data['Close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "    data['macd'] = macd_indicator.macd()\n",
    "    data['macd_signal'] = macd_indicator.macd_signal()\n",
    "\n",
    "    # Crear instancia del indicador EMA con períodos de 13 y 48\n",
    "    ema_13_indicator = ta.trend.EMAIndicator(close=data['Close'], window=13)\n",
    "    ema_48_indicator = ta.trend.EMAIndicator(close=data['Close'], window=48)\n",
    "        \n",
    "    # Calcular las EMAs 13 y 48 \n",
    "    data['Ema 13'] = ema_13_indicator.ema_indicator()\n",
    "    data['Ema 48'] = ema_48_indicator.ema_indicator()\n",
    "    # Inicializar el indicador EMA con una ventana de 200 períodos\n",
    "    ema_indicator = ta.trend.EMAIndicator(close=data['Close'], window=200)\n",
    "    # Calcular la EMA 200\n",
    "\n",
    "    data['Ema 200'] = ema_indicator.ema_indicator()\n",
    "    data[\"Long\"] = False\n",
    "    data[\"Short\"] = False\n",
    "\n",
    "    for i in range(len(data[\"Close\"])):\n",
    "\n",
    "        if i + 10 < len(data[\"Close\"]):\n",
    "            if data[\"Close\"][i] > data[\"Close\"][i + 10]:\n",
    "                data.loc[i, \"Long\"] = True\n",
    "            elif data[\"Close\"][i] < data[\"Close\"][i + 10]:\n",
    "                data.loc[i, \"Short\"] = True\n",
    "    data=data\n",
    "    return data\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_data(url).iloc[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_long(data):\n",
    "\n",
    "    X = data[['RSI', 'Ema 13', 'Ema 200']]\n",
    "    y = data['Long']\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializar el modelo de regresión logística\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Imprimir el informe de clasificación\n",
    "    #print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_long(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_short(data):\n",
    "\n",
    "    X = data[['RSI', 'Ema 13', 'Ema 200']]\n",
    "    y = data['Short']\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializar el modelo de regresión logística\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Imprimir el informe de clasificación\n",
    "    #print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_short(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine_long(data):\n",
    "\n",
    "    X = data[['RSI', 'Ema 13', 'Ema 200']]\n",
    "    y = data['Long']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializar el clasificador SVM\n",
    "    clf = svm.SVC(kernel='linear')  # Puedes cambiar el kernel según tus necesidades (lineal, polinomial, RBF, etc.)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine_long(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine_short(data):\n",
    "\n",
    "    X = data[['RSI', 'Ema 13', 'Ema 200']]\n",
    "    y = data['Short']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Inicializar el clasificador SVM\n",
    "    clf = svm.SVC(kernel='linear')  # Puedes cambiar el kernel según tus necesidades (lineal, polinomial, RBF, etc.)\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine_short(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_long(data):\n",
    "\n",
    "    X = data[['RSI', 'Ema 13', 'Ema 200']]\n",
    "    y = data['Long']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convertir los datos a un formato específico para XGBoost (DMatrix)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Definir los parámetros del modelo\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # Problema de clasificación binaria\n",
    "        'eval_metric': 'logloss',  # Métrica de evaluación\n",
    "        'eta': 0.1,  # Tasa de aprendizaje\n",
    "        'max_depth': 6,  # Profundidad máxima del árbol\n",
    "        'subsample': 0.8,  # Proporción de muestras utilizadas para entrenar cada árbol\n",
    "        'colsample_bytree': 0.8  # Proporción de características utilizadas para entrenar cada árbol\n",
    "    }\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    num_round = 100  # Número de iteraciones de entrenamiento (número de árboles)\n",
    "    model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred_proba = model.predict(dtest)\n",
    "    y_pred = [1 if pred > 0.5 else 0 for pred in y_pred_proba]  # Convertir probabilidades en etiquetas binarias\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_long(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost_short(data):\n",
    "\n",
    "    X = data[['RSI', 'Ema 13', 'Ema 200']]\n",
    "    y = data['Short']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convertir los datos a un formato específico para XGBoost (DMatrix)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Definir los parámetros del modelo\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',  # Problema de clasificación binaria\n",
    "        'eval_metric': 'logloss',  # Métrica de evaluación\n",
    "        'eta': 0.1,  # Tasa de aprendizaje\n",
    "        'max_depth': 6,  # Profundidad máxima del árbol\n",
    "        'subsample': 0.8,  # Proporción de muestras utilizadas para entrenar cada árbol\n",
    "        'colsample_bytree': 0.8  # Proporción de características utilizadas para entrenar cada árbol\n",
    "    }\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    num_round = 100  # Número de iteraciones de entrenamiento (número de árboles)\n",
    "    model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred_proba = model.predict(dtest)\n",
    "    y_pred = [1 if pred > 0.5 else 0 for pred in y_pred_proba]  # Convertir probabilidades en etiquetas binarias\n",
    "\n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost_short(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optimizing using \"Long\" as the target variable\n",
    "X = data[['RSI', 'Ema 13', 'Ema 200']]\n",
    "y = data['Long']\n",
    "\n",
    "# Optimizing Logistic Regression\n",
    "def optimize_logistic_regression(trial):\n",
    "    C = trial.suggest_loguniform('C', 0.01, 10) # Regularization parameter\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000) # Maximum number of iterations\n",
    "    \n",
    "    model = LogisticRegression(C=C, max_iter=max_iter)\n",
    "    scores = cross_val_score(model, X, y, cv=5) # 5-fold cross-validation\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# Optimizing SVM\n",
    "def optimize_svm(trial):\n",
    "    C = trial.suggest_loguniform('C', 0.01, 10) # Regularization parameter\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']) # Kernel type\n",
    "    \n",
    "    model = svm.SVC(C=C, kernel=kernel)\n",
    "    scores = cross_val_score(model, X, y, cv=5) # 5-fold cross-validation\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# Optimizing XGBoost\n",
    "def optimize_xgboost(trial):\n",
    "    eta = trial.suggest_loguniform('eta', 0.01, 0.1) # Learning rate\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10) # Maximum depth of the tree\n",
    "    subsample = trial.suggest_uniform('subsample', 0.6, 1.0) # Subsample ratio of the training instances\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.6, 1.0) # Subsample ratio of columns when constructing each tree\n",
    "    \n",
    "    model = xgb.XGBClassifier(eta=eta, max_depth=max_depth, subsample=subsample, colsample_bytree=colsample_bytree)\n",
    "    scores = cross_val_score(model, X, y, cv=5) # 5-fold cross-validation\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# Ojective function for Optuna\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical('model', ['logistic_regression', 'svm', 'xgboost'])\n",
    "    \n",
    "    if model_name == 'logistic_regression':\n",
    "        return optimize_logistic_regression(trial)\n",
    "    elif model_name == 'svm':\n",
    "        return optimize_svm(trial)\n",
    "    elif model_name == 'xgboost':\n",
    "        return optimize_xgboost(trial)\n",
    "\n",
    "# Optimize hyperparameters using Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100) # We decided to do 100 trials becasue we noticed that the the study convverges\n",
    "\n",
    "# Get the best hyperparameters and corresponding score\n",
    "best_params = study.best_trial.params\n",
    "best_score = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Print optimal hyperparameters\n",
    "for param, value in best_params.items():\n",
    "    print(f\"Optimal {param}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing using \"Short\" as the target variable\n",
    "X = data[['RSI', 'Ema 13', 'Ema 200']]\n",
    "y = data['Short']\n",
    "\n",
    "# Optimizing Logistic Regression\n",
    "def optimize_logistic_regression(trial):\n",
    "    C = trial.suggest_loguniform('C', 0.01, 10) # Regularization parameter\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000) # Maximum number of iterations\n",
    "    \n",
    "    model = LogisticRegression(C=C, max_iter=max_iter)\n",
    "    scores = cross_val_score(model, X, y, cv=5) # 5-fold cross-validation\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# Optimizing SVM\n",
    "def optimize_svm(trial):\n",
    "    C = trial.suggest_loguniform('C', 0.01, 10) # Regularization parameter\n",
    "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly']) # Kernel type\n",
    "    \n",
    "    model = svm.SVC(C=C, kernel=kernel)\n",
    "    scores = cross_val_score(model, X, y, cv=5) # 5-fold cross-validation\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# Optimizing XGBoost\n",
    "def optimize_xgboost(trial):\n",
    "    eta = trial.suggest_loguniform('eta', 0.01, 0.1) # Learning rate\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10) # Maximum depth of the tree\n",
    "    subsample = trial.suggest_uniform('subsample', 0.6, 1.0) # Subsample ratio of the training instances\n",
    "    colsample_bytree = trial.suggest_uniform('colsample_bytree', 0.6, 1.0) # Subsample ratio of columns when constructing each tree\n",
    "    \n",
    "    model = xgb.XGBClassifier(eta=eta, max_depth=max_depth, subsample=subsample, colsample_bytree=colsample_bytree)\n",
    "    scores = cross_val_score(model, X, y, cv=5) # 5-fold cross-validation\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "# Ojective function for Optuna\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical('model', ['logistic_regression', 'svm', 'xgboost'])\n",
    "    \n",
    "    if model_name == 'logistic_regression':\n",
    "        return optimize_logistic_regression(trial)\n",
    "    elif model_name == 'svm':\n",
    "        return optimize_svm(trial)\n",
    "    elif model_name == 'xgboost':\n",
    "        return optimize_xgboost(trial)\n",
    "\n",
    "# Optimize hyperparameters using Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100) # We decided to do 100 trials becasue we noticed that the the study converges\n",
    "\n",
    "# Get the best hyperparameters and corresponding score\n",
    "best_params = study.best_trial.params\n",
    "best_score = study.best_value\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Print optimal hyperparameters\n",
    "for param, value in best_params.items():\n",
    "    print(f\"Optimal {param}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_logistic_regression(data, model, target, take_profit, stop_loss, initial_capital):\n",
    "    # Crear una copia de los datos\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Crear una nueva columna con las predicciones del modelo\n",
    "    data['Prediction'] = model.predict(data[['RSI', 'Ema 13', 'Ema 200']])\n",
    "    \n",
    "    # Calcular el rendimiento diario\n",
    "    data['Return'] = data['Closet-1'] / data['Close'] - 1\n",
    "    \n",
    "    # Calcular el rendimiento diario de la estrategia\n",
    "    data['Strategy Return'] = data['Return'] * data['Prediction']\n",
    "    \n",
    "    # Calcular el rendimiento acumulado de la estrategia\n",
    "    data['Cumulative Strategy Return'] = (data['Strategy Return'] + 1).cumprod()\n",
    "    \n",
    "    # Inicializar el capital\n",
    "    capital = initial_capital\n",
    "    \n",
    "    # Inicializar el estado de la operación\n",
    "    in_trade = False\n",
    "    \n",
    "    # Inicializar el precio de entrada\n",
    "    entry_price = 0\n",
    "    \n",
    "    # Recorrer los datos\n",
    "    for i in range(len(data)):\n",
    "        # Si estamos en una operación\n",
    "        if in_trade:\n",
    "            # Si alcanzamos el take profit o el stop loss\n",
    "            if data['Close'].iloc[i] >= entry_price * (1 + take_profit) or data['Close'].iloc[i] <= entry_price * (1 - stop_loss):\n",
    "                # Salir de la operación\n",
    "                in_trade = False\n",
    "        # Si no estamos en una operación y el modelo predice una entrada\n",
    "        elif data['Prediction'].iloc[i] == 1:\n",
    "            # Entrar en la operación\n",
    "            in_trade = True\n",
    "            entry_price = data['Close'].iloc[i]\n",
    "            capital -= entry_price  # Descontar el precio de entrada del capital\n",
    "    \n",
    "    # Graficar el rendimiento acumulado de la estrategia\n",
    "    data['Cumulative Strategy Return'].plot(figsize=(10, 6))\n",
    "    plt.title(f'Cumulative Strategy Return ({target})')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(data[target], data['Prediction'])\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Imprimir el informe de clasificación\n",
    "    print(classification_report(data[target], data['Prediction']))\n",
    "    \n",
    "    # Imprimir la matriz de confusión\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(data[target], data['Prediction']))\n",
    "    \n",
    "    # Imprimir el capital final\n",
    "    print(\"Final capital:\", capital)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar la estrategia con el modelo de regresión logística para \"Long\"\n",
    "model = LogisticRegression(C=0.01, max_iter=100)\n",
    "model.fit(data[['RSI', 'Ema 13', 'Ema 200']], data['Long'])\n",
    "backtest_logistic_regression(data, model, 'Long', 0.05, 0.02, 100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar la estrategia con el modelo de regresión logística para \"Short\"\n",
    "model = LogisticRegression(C=0.01, max_iter=100)\n",
    "model.fit(data[['RSI', 'Ema 13', 'Ema 200']], data['Short'])\n",
    "backtest_logistic_regression(data, model, 'Short', 0.05, 0.02, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion de backtest para SVM\n",
    "\n",
    "def backtest_svm(data, model, target, take_profit, stop_loss, initial_capital):\n",
    "    # Crear una copia de los datos\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Crear una nueva columna con las predicciones del modelo\n",
    "    data['Prediction'] = model.predict(data[['RSI', 'Ema 13', 'Ema 200']])\n",
    "    \n",
    "    # Calcular el rendimiento diario\n",
    "    data['Return'] = data['Closet-1'] / data['Close'] - 1\n",
    "    \n",
    "    # Calcular el rendimiento diario de la estrategia\n",
    "    data['Strategy Return'] = data['Return'] * data['Prediction']\n",
    "    \n",
    "    # Calcular el rendimiento acumulado de la estrategia\n",
    "    data['Cumulative Strategy Return'] = (data['Strategy Return'] + 1).cumprod()\n",
    "    \n",
    "    # Inicializar el capital\n",
    "    capital = initial_capital\n",
    "    \n",
    "    # Inicializar el estado de la operación\n",
    "    in_trade = False\n",
    "    \n",
    "    # Inicializar el precio de entrada\n",
    "    entry_price = 0\n",
    "    \n",
    "    # Recorrer los datos\n",
    "    for i in range(len(data)):\n",
    "        # Si estamos en una operación\n",
    "        if in_trade:\n",
    "            # Si alcanzamos el take profit o el stop loss\n",
    "            if data['Close'].iloc[i] >= entry_price * (1 + take_profit) or data['Close'].iloc[i] <= entry_price * (1 - stop_loss):\n",
    "                # Salir de la operación\n",
    "                in_trade = False\n",
    "        # Si no estamos en una operación y el modelo predice una entrada\n",
    "        elif data['Prediction'].iloc[i] == 1:\n",
    "            # Entrar en la operación\n",
    "            in_trade = True\n",
    "            entry_price = data['Close'].iloc[i]\n",
    "            capital -= entry_price  # Descontar el precio de entrada del capital\n",
    "    \n",
    "    # Graficar el rendimiento acumulado de la estrategia\n",
    "    data['Cumulative Strategy Return'].plot(figsize=(10, 6))\n",
    "    plt.title(f'Cumulative Strategy Return ({target})')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(data[target], data['Prediction'])\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Imprimir el informe de clasificación\n",
    "    print(classification_report(data[target], data['Prediction']))\n",
    "    \n",
    "    # Imprimir la matriz de confusión\n",
    "    print(\"Confusion Matrix:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar la estrategia con el modelo SVM para \"Long\"\n",
    "model = svm.SVC(C=0.01, kernel='rbf')\n",
    "model.fit(data[['RSI', 'Ema 13', 'Ema 200']], data['Long'])\n",
    "backtest_svm(data, model, 'Long', 0.05, 0.02, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar la estrategia con el modelo SVM para \"Short\"\n",
    "model = svm.SVC(C=0.01, kernel='rbf')\n",
    "model.fit(data[['RSI', 'Ema 13', 'Ema 200']], data['Short'])\n",
    "backtest_svm(data, model, 'Short', 0.05, 0.02, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion de backtest para XGBoost\n",
    "\n",
    "def backtest_xgboost(data, model, target, take_profit, stop_loss, initial_capital):\n",
    "    # Crear una copia de los datos\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Crear una nueva columna con las predicciones del modelo\n",
    "    data['Prediction'] = model.predict(data[['RSI', 'Ema 13', 'Ema 200']])\n",
    "    \n",
    "    # Calcular el rendimiento diario\n",
    "    data['Return'] = data['Closet-1'] / data['Close'] - 1\n",
    "    \n",
    "    # Calcular el rendimiento diario de la estrategia\n",
    "    data['Strategy Return'] = data['Return'] * data['Prediction']\n",
    "    \n",
    "    # Calcular el rendimiento acumulado de la estrategia\n",
    "    data['Cumulative Strategy Return'] = (data['Strategy Return'] + 1).cumprod()\n",
    "    \n",
    "    # Inicializar el capital\n",
    "    capital = initial_capital\n",
    "    \n",
    "    # Inicializar el estado de la operación\n",
    "    in_trade = False\n",
    "    \n",
    "    # Inicializar el precio de entrada\n",
    "    entry_price = 0\n",
    "    \n",
    "    # Recorrer los datos\n",
    "    for i in range(len(data)):\n",
    "        # Si estamos en una operación\n",
    "        if in_trade:\n",
    "            # Si alcanzamos el take profit o el stop loss\n",
    "            if data['Close'].iloc[i] >= entry_price * (1 + take_profit) or data['Close'].iloc[i] <= entry_price * (1 - stop_loss):\n",
    "                # Salir de la operación\n",
    "                in_trade = False\n",
    "        # Si no estamos en una operación y el modelo predice una entrada\n",
    "        elif data['Prediction'].iloc[i] == 1:\n",
    "            # Entrar en la operación\n",
    "            in_trade = True\n",
    "            entry_price = data['Close'].iloc[i]\n",
    "            capital -= entry_price  # Descontar el precio de entrada del capital\n",
    "    \n",
    "    # Graficar el rendimiento acumulado de la estrategia\n",
    "    data['Cumulative Strategy Return'].plot(figsize=(10, 6))\n",
    "    plt.title(f'Cumulative Strategy Return ({target})')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calcular la precisión del modelo\n",
    "    accuracy = accuracy_score(data[target], data['Prediction'])\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Imprimir el informe de clasificación\n",
    "    print(classification_report(data[target], data['Prediction']))\n",
    "    \n",
    "    # Imprimir la matriz de confusión\n",
    "    print(\"Confusion Matrix:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar la estrategia con el modelo XGBoost para \"Long\"\n",
    "model = xgb.XGBClassifier(eta=0.1, max_depth=6, subsample=0.8, colsample_bytree=0.8)\n",
    "model.fit(data[['RSI', 'Ema 13', 'Ema 200']], data['Long'])\n",
    "backtest_xgboost(data, model, 'Long', 0.05, 0.02, 100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar la estrategia con el modelo XGBoost para \"Short\"\n",
    "model = xgb.XGBClassifier(eta=0.1, max_depth=6, subsample=0.8, colsample_bytree=0.8)\n",
    "model.fit(data[['RSI', 'Ema 13', 'Ema 200']], data['Short'])\n",
    "backtest_xgboost(data, model, 'Short', 0.05, 0.02, 100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
